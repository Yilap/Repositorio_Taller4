ifelse(m_train$P6210  == 6, 16,
ifelse(m_train$P6210  == 9, 0, 0)))))
m_test$Añoseduc <- ifelse(m_test$P6210 == 3, 5,
ifelse(m_test$P6210  == 4, 9,
ifelse(m_test$P6210  == 5, 11,
ifelse(m_test$P6210  == 6, 16,
ifelse(m_test$P6210  == 9, 0, 0)))))
missing_count <- colSums(is.na(m_train))
print(missing_count)
# Calcular la suma de los años de educación para cada hogar que tenga al menos una persona en edad de trabajar
#sum_añoseduc <- aggregate(m_train$Añoseduc[m_train$Pet == 1], by = list(m_train$id[m_train$Pet == 1]), sum)
#colnames(sum_añoseduc) <- c("id", "total_añoseduc") # Renombrar las columnas
#m_train <- merge(m_train, sum_añoseduc, by = "id")
#sum_añoseduc2 <- aggregate(m_test$Añoseduc[m_test$Pet == 1], by = list(m_test$id[m_test$Pet == 1]), sum)
#colnames(sum_añoseduc2) <- c("id", "total_añoseduc") # Renombrar las columnas
#m_test <- merge(m_test, sum_añoseduc2, by = "id")
#rm(sum_añoseduc, sum_añoseduc2)
# Creamos la nueva variable que cuenta las personas que están ocupadas en el hogar, y hallamos el porcentaje de personas
#ocupadas en el hogar
m_test$Oc[is.na(m_test$Oc)] <- 0
m_train$Oc[is.na(m_train$Oc)] <- 0
m_test <- m_test %>%
group_by(id) %>%
mutate(Suma_Ocu = sum(Oc))
m_test$PorcentajeOcupados <-  m_test$Suma_Ocu / m_test$Nper
m_train <- m_train %>%
group_by(id) %>%
mutate(Suma_Ocu = sum(Oc))
m_train$PorcentajeOcupados <-  m_train$Suma_Ocu / m_train$Nper
# Creamos la nueva variable que suma los años para cada valor repetido de id
m_test <- m_test %>%
group_by(id) %>%
mutate(suma_años = sum(Añoseduc))
m_test$EducaciónPromedio <-  m_test$suma_años / m_test$Nper
m_train <- m_train %>%
group_by(id) %>%
mutate(suma_años = sum(Añoseduc))
m_train$EducaciónPromedio <-  m_train$suma_años / m_train$Nper
length(unique(m_test$id))  #validamos que no hallamos perdido hogares en el proceso
length(unique(m_train$id)) #validamos que no hallamos perdido hogares en el proceso
# Renombramos variable P6426 a Antiguedad en el actual trabajo
m_train <- rename(m_train, AntiguedadTrabajo = P6426)
m_test <- rename(m_test, AntiguedadTrabajo = P6426)
m_train$AntiguedadTrabajo[m_train$Oc == 0] <- 0
m_test$AntiguedadTrabajo[m_test$Oc == 0] <- 0
# Volvemos la categórica P6430 "Tipo de trabajo" a dicótomas
m_train$P6430[m_train$Oc == 0] <- 0
m_test$P6430[m_test$Oc == 0] <- 0
m_test <- m_test %>%
mutate(P6430 = factor(P6430,
levels = c(0,1,2,3,4,5,6,7,8,9),
labels = c("No trabaja",
"Empleado Empresa Particular",
"Empleado del Gobierno",
"Empleado Doméstico",
"Cuenta Propia",
"Empleador",
"Trabajador Familiar sin Remuneración",
"Trabajador sin remuneración en empresas",
"Jornalero o Peón",
"Otro")))
m_train <- m_train %>%
mutate(P6430 = factor(P6430,
levels = c(0,1,2,3,4,5,6,7,8,9),
labels = c("No trabaja",
"Empleado Empresa Particular",
"Empleado del Gobierno",
"Empleado Doméstico",
"Cuenta Propia",
"Empleador",
"Trabajador Familiar sin Remuneración",
"Trabajador sin remuneración en empresas",
"Jornalero o Peón",
"Otro")))
m_train <- rename(m_train, TipoDeTrabajo = P6430)
m_test <- rename(m_test, TipoDeTrabajo = P6430)
## Ya tenemos todas las variables, las operaciones que provienen de personas las asignamos para todo el hogar, especificamente
##para el Jefe de Hogar, por lo tanto, procedemos a generar las data por hogar nuevamente.
m_train <- rename(m_train, JefeHogar = P6050)
m_test <- rename(m_test, JefeHogar = P6050)
m_train <- m_train %>% filter(JefeHogar == 1)
m_test <- m_test %>% filter(JefeHogar == 1)
train_final <-subset(m_train, select = c("PorcentajeOcupados","ViveEnCabecera","JefeMujer","PersonaPorCuarto","TipoVivienda","RegimenSalud","EducaciónPromedio","AntiguedadTrabajo","TipoDeTrabajo","Pobre","Lp","Ingtotugarr"))
test_final <-subset(m_test, select = c("PorcentajeOcupados","ViveEnCabecera","JefeMujer","PersonaPorCuarto","TipoVivienda","RegimenSalud","EducaciónPromedio","AntiguedadTrabajo","TipoDeTrabajo"))
## Tratamiento de NA (Missing Values)
# Identificamos los NA para las bases de datos
missing_count <- colSums(is.na(train_final))
print(missing_count)
missing_count <- colSums(is.na(test_final))
print(missing_count)
test_final$RegimenSalud [is.na(test_final$RegimenSalud )] <- 0 #detectamos un missing value en Regime de Salud, lo dejamos cero considerao que al ser
train_final$RegimenSalud [is.na(train_final$RegimenSalud )] <- 0 #insignificante no afecta el poder estadístico
missing_count <- colSums(is.na(test_final))
print(missing_count)
test_final$RegimenSalud [is.na(test_final$RegimenSalud)] <- 0 #detectamos un missing value en Regime de Salud, lo dejamos cero considerao que al ser
train_final$RegimenSalud [is.na(train_final$RegimenSalud)] <- 0 #insignificante no afecta el poder estadístico
missing_count <- colSums(is.na(test_final))
print(missing_count)
rm("m_test","m_train","test_hogares","test_personas","train_hogares","train_personas","missing_count")
lineal1 <- train(
modelo,
data = training,
method = "lm",
trControl = control,
preProcess = c("center", "scale")
)
clear
rm
rm(list = ls())
setwd("C:/Users/Yilmer Palacios/Desktop/Repositorios GitHub/Repositorio_taller3")
setwd("C:/Users/Yilmer Palacios/Desktop/Repositorios GitHub/Repositorio_Taller4")
train <- read_csv("stores/Data_Kaggle/train.csv")
# Loading Libraries ----
rm(list = ls())
# install.packages("pacman")
library("pacman")
p_load("tidyverse",
"sf",
"naniar",
"tidymodels",
"readxl",
"psych",
"ranger",
"glmnet",
"naniar",
"tidyverse",
"caret",
"glmnet",
"ggplot2",
"ggraph",
"gt")
#setwd("/Users/betinacortes/Desktop/Repositorio_taller3")
setwd("C:/Users/Yilmer Palacios/Desktop/Repositorios GitHub/Repositorio_Taller4")
# Importing Dataset ----
# Removing City and operation type as they don't add information
train <- read_csv("stores/Data_Kaggle/train.csv")
# Removing City and operation type as they don't add information
train <- read_csv("stores/Data_Kaggle/train.csv")
test <- read_csv("stores/Data_Kaggle/test.csv")
View(train)
View(train)
View(test)
## Checking missing values ----
miss_var_summary(train)
miss_var_summary(test)
p_load("tm",
"tidyverse",
"sf",
"naniar",
"tidymodels",
"readxl",
"psych",
"ranger",
"glmnet",
"naniar",
"tidyverse",
"caret",
"glmnet",
"ggplot2",
"ggraph",
"gt")
texts<-VCorpus(VectorSource(train.csv$text))
texts<-VCorpus(VectorSource(train$text))
texts
View(test)
View(texts)
texts
dtm<-DocumentTermMatrix(texts)
dtm
dtm
View(dtm)
inspect(dtm)
# Loading Libraries ----
rm(list = ls())
# install.packages("pacman")
library("pacman")
p_load("tm",
"tidyverse",
"sf",
"naniar",
"tidymodels",
"readxl",
"psych",
"ranger",
"glmnet",
"naniar",
"tidyverse",
"caret",
"glmnet",
"ggplot2",
"ggraph",
"gt")
#setwd("/Users/betinacortes/Desktop/Repositorio_taller3")
setwd("C:/Users/Yilmer Palacios/Desktop/Repositorios GitHub/Repositorio_Taller4")
# Importing Dataset ----
# Removing City and operation type as they don't add information
train <- read_csv("stores/Data_Kaggle/train.csv")
test <- read_csv("stores/Data_Kaggle/test.csv")
texts<-VCorpus(VectorSource(train$text))
texts
dtm<-DocumentTermMatrix(texts)
dtm
inspect(dtm)
train <- read_csv("stores/Data_Kaggle/train.csv",header = TRUE,sep=";")
###############################################################
# Loading Libraries ----
rm(list = ls())
# install.packages("pacman")
library("pacman")
p_load("tm
# Loading Libraries ----
rm(list = ls())
# install.packages("pacman")
# Loading Libraries ----
rm(list = ls())
# install.packages("pacman")
library("pacman")
p_load("tm",
"tidyverse",
"sf",
"naniar",
"tidymodels",
"readxl",
"psych",
"ranger",
"glmnet",
"naniar",
"tidyverse",
"caret",
"glmnet",
"ggplot2",
"ggraph",
"gt")
#setwd("/Users/betinacortes/Desktop/Repositorio_taller3")
setwd("C:/Users/Yilmer Palacios/Desktop/Repositorios GitHub/Repositorio_Taller4")
train <- read_csv("stores/Data_Kaggle/train.csv",header = TRUE,sep=";")
train <- read.csv("stores/Data_Kaggle/train.csv",header = TRUE,sep=";")
test <- read.csv("stores/Data_Kaggle/test.csv",header = TRUE,sep=";")
View(test)
View(train)
rm(list = ls())
# Importing Dataset ----
# Removing City and operation type as they don't add information
train <- read.csv("stores/Data_Kaggle/train.csv",header = TRUE,sep=",")
test <- read.csv("stores/Data_Kaggle/test.csv",header = TRUE,sep=",")
View(test)
View(train)
texts<-VCorpus(VectorSource(train$text))
texts
dtm<-DocumentTermMatrix(texts)
dtm
inspect(dtm)
View(dtm)
dtm<-DocumentTermMatrix(texts,control=list(stopwords=c("con","del","las","los","para","por","que","es","una")))
inspect(dtm)
dtm_idf<-DocumentTermMatrix(texts,control=list(weighting=weightTfIdf,stopwords=c("con","del","las","los","para","por","que","es","una")))
dtm
inspect(dtm)
dtm_idf<-DocumentTermMatrix(texts,control=list(weighting=weightTfIdf,stopwords=c("con","del","las","los","para","por","que","es","una"
dtm_idf<-DocumentTermMatrix(texts,control=list(weighting=weightTfIdf,stopwords=c("con","del","las","los","para","por","que","es","una"
dtm_idf<-DocumentTermMatrix(texts,control=list(weighting=weightTfIdf,stopwords=c("con","del","las","los","para","por","que","es","una","como","esta","este","más","nos")))
dtm
inspect(dtm)
rm(list = ls())
# Importing Dataset ----
# Removing City and operation type as they don't add information
train <- read.csv("stores/Data_Kaggle/train.csv",header = TRUE,sep=",")
test <- read.csv("stores/Data_Kaggle/test.csv",header = TRUE,sep=",")
texts<-VCorpus(VectorSource(train$text))
texts
dtm_idf<-DocumentTermMatrix(texts,
control=list(weighting=weightTfIdf,
stopwords=c("con","del","las","los","para","por","que",
"es","una","como","esta","este","más","nos")))
dtm
dtm_idf
inspect(dtm_idf)
tm_idf<-DocumentTermMatrix(texts,
control=list(weighting=weightTfIdf,
stopwords=c("con","del","las","los","para","por","que",
"es","una","como","esta","este","más","nos"
,"son","sus","hoy","nos","nos","nos")))
dtm_idf
inspect(dtm_idf)
rm(list = ls(dtm_idf))
rm((dtm_idf))
rm("dtm_idf")
dtm_idf<-DocumentTermMatrix(texts,
control=list(weighting=weightTfIdf,
stopwords=c("con","del","las","los","para","por","que",
"es","una","como","esta","este","más","nos"
,"son","sus","hoy","nos","nos","nos")))
dtm_idf
inspect(dtm_idf)
terms_freq <- findFreqTerms(dtm, lowfreq = 1)
terms_freq <- findFreqTerms(dtm_idf, lowfreq = 1)
freq_table <- data.frame(term = terms_freq, freq = colSums(as.matrix(dtm_idf[,terms_freq])))
print(freq_table)
# Loading Libraries ----
rm(list = ls())
# install.packages("pacman")
library("pacman")
p_load("tm",
"tidyverse",
"sf",
"naniar",
"tidymodels",
"readxl",
"psych",
"ranger",
"glmnet",
"naniar",
"tidyverse",
"caret",
"glmnet",
"ggplot2",
"ggraph",
"gt")
#setwd("/Users/betinacortes/Desktop/Repositorio_taller3")
setwd("C:/Users/Yilmer Palacios/Desktop/Repositorios GitHub/Repositorio_Taller4")
# Importing Dataset ----
# Removing City and operation type as they don't add information
train <- read.csv("stores/Data_Kaggle/train.csv",header = TRUE,sep=",")
test <- read.csv("stores/Data_Kaggle/test.csv",header = TRUE,sep=",")
texts<-VCorpus(VectorSource(train$text))
texts
rm("dtm_idf")
texts <- tm_map(texts, removePunctuation)
texts <- tm_map(texts, content_transformer(tolower))
texts <- tm_map(texts, removeWords, stopwords("spanish"))
dtm_idf<-DocumentTermMatrix(texts,
control=list(weighting=weightTfIdf)
dtm_idf
dtm_idf<-DocumentTermMatrix(texts,
control=list(weighting=weightTfIdf,
stopwords=c("con")))
dtm_idf
inspect(dtm_idf)
freq_table <- data.frame(term = terms_freq, freq = colSums(as.matrix(dtm_idf[,terms_freq])))
terms_freq <- findFreqTerms(dtm_idf, lowfreq = 1)
freq_table <- data.frame(term = terms_freq, freq = colSums(as.matrix(dtm_idf[,terms_freq])))
print(freq_table)
texts <- tm_map(texts, content_transformer(gsub), pattern = "\\b[0-9]+\\b", replacement = "")
rm("dtm_idf")
rm(list = ls())
# Importing Dataset ----
# Removing City and operation type as they don't add information
train <- read.csv("stores/Data_Kaggle/train.csv",header = TRUE,sep=",")
test <- read.csv("stores/Data_Kaggle/test.csv",header = TRUE,sep=",")
texts<-VCorpus(VectorSource(train$text))
texts
#limpiamos el corpus texts
texts <- tm_map(texts, removePunctuation)
texts <- tm_map(texts, content_transformer(tolower))
texts <- tm_map(texts, removeWords, stopwords("spanish"))
texts <- tm_map(texts, content_transformer(gsub), pattern = "[!|?]", replacement = "")
texts <- tm_map(texts, content_transformer(gsub), pattern = "\\b[0-9]+\\b", replacement = "")
texts <- tm_map(texts, content_transformer(gsub), pattern = "\"", replacement = "")
dtm_idf<-DocumentTermMatrix(texts,
control=list(weighting=weightTfIdf,
stopwords=c("con", "si")))
dtm_idf
inspect(dtm_idf)
#revisamos frecuencias
terms_freq <- findFreqTerms(dtm_idf, lowfreq = 1)
freq_table <- data.frame(term = terms_freq, freq = colSums(as.matrix(dtm_idf[,terms_freq])))
print(freq_table)
texts <- tm_map(texts, content_transformer(gsub), pattern = "[\U0001F600-\U0001F6FF]", replacement = "")
# Loading Libraries ----
rm(list = ls())
# install.packages("pacman")
library("pacman")
p_load("tm",
"tidyverse",
"sf",
"naniar",
"tidymodels",
"readxl",
"psych",
"ranger",
"glmnet",
"naniar",
"tidyverse",
"caret",
"glmnet",
"ggplot2",
"ggraph",
"gt")
#setwd("/Users/betinacortes/Desktop/Repositorio_taller3")
setwd("C:/Users/Yilmer Palacios/Desktop/Repositorios GitHub/Repositorio_Taller4")
# Importing Dataset ----
# Removing City and operation type as they don't add information
train <- read.csv("stores/Data_Kaggle/train.csv",header = TRUE,sep=",")
test <- read.csv("stores/Data_Kaggle/test.csv",header = TRUE,sep=",")
texts<-VCorpus(VectorSource(train$text))
texts
rm("dtm_idf")
#limpiamos el corpus texts
texts <- tm_map(texts, removePunctuation)
texts <- tm_map(texts, content_transformer(tolower))
texts <- tm_map(texts, removeWords, stopwords("spanish"))
texts <- tm_map(texts, content_transformer(gsub), pattern = "[!|?]", replacement = "")
texts <- tm_map(texts, content_transformer(gsub), pattern = "\\b[0-9]+\\b", replacement = "")
texts <- tm_map(texts, content_transformer(gsub), pattern = "\"", replacement = "")
texts <- tm_map(texts, content_transformer(gsub), pattern = "[\U0001F600-\U0001F6FF]", replacement = "")
p_load("tm",
"stringi",
"tidyverse",
"sf",
"naniar",
"tidymodels",
"readxl",
"psych",
"ranger",
"glmnet",
"naniar",
"tidyverse",
"caret",
"glmnet",
"ggplot2",
"ggraph",
"gt")
# Importing Dataset ----
# Removing City and operation type as they don't add information
train <- read.csv("stores/Data_Kaggle/train.csv",header = TRUE,sep=",")
test <- read.csv("stores/Data_Kaggle/test.csv",header = TRUE,sep=",")
texts<-VCorpus(VectorSource(train$text))
texts
#limpiamos el corpus texts
texts <- tm_map(texts, removePunctuation)
texts <- tm_map(texts, content_transformer(tolower))
texts <- tm_map(texts, removeWords, stopwords("spanish"))
texts <- tm_map(texts, content_transformer(gsub), pattern = "[!|?]", replacement = "")
texts <- tm_map(texts, content_transformer(gsub), pattern = "\\b[0-9]+\\b", replacement = "")
texts <- tm_map(texts, content_transformer(gsub), pattern = "\"", replacement = "")
corpus <- tm_map(corpus, content_transformer(function(x) stri_replace_all_regex(x, "\\p{Emoji}", "")))
texts <- tm_map(texts, content_transformer(function(x) stri_replace_all_regex(x, "\\p{Emoji}", "")))
dtm_idf<-DocumentTermMatrix(texts,
control=list(weighting=weightTfIdf,
stopwords=c("con", "si")))
dtm_idf
inspect(dtm_idf)
#revisamos frecuencias
terms_freq <- findFreqTerms(dtm_idf, lowfreq = 1)
freq_table <- data.frame(term = terms_freq, freq = colSums(as.matrix(dtm_idf[,terms_freq])))
print(freq_table)
texts <- tm_map(texts, content_transformer(gsub), pattern = "[!|?|¡|¿]", replacement = "")
dtm_idf<-DocumentTermMatrix(texts,
control=list(weighting=weightTfIdf,
stopwords=c("con", "si")))
dtm_idf
inspect(dtm_idf)
#revisamos frecuencias
terms_freq <- findFreqTerms(dtm_idf, lowfreq = 1)
freq_table <- data.frame(term = terms_freq, freq = colSums(as.matrix(dtm_idf[,terms_freq])))
print(freq_table)
texts <- tm_map(texts, content_transformer(gsub), pattern = "[!|?|¡|¿|“]", replacement = "")
texts <- tm_map(texts, content_transformer(gsub), pattern = "[!|?|¡|¿|“|”|´|´|‘|’]", replacement = "")
dtm_idf<-DocumentTermMatrix(texts,
control=list(weighting=weightTfIdf,
stopwords=c("con", "si")))
dtm_idf
inspect(dtm_idf)
#revisamos frecuencias
terms_freq <- findFreqTerms(dtm_idf, lowfreq = 1)
freq_table <- data.frame(term = terms_freq, freq = colSums(as.matrix(dtm_idf[,terms_freq])))
print(freq_table)
View(test)
View(train)
text <- stri_trans_general(str = train$text, id = "Latin-ASCII")
p_load("tm",
"stringi",
"proxy"
"tidyverse",
p_load("tm",
"stringi",
"proxy",
"tidyverse",
"sf",
"naniar",
"tidymodels",
"readxl",
"psych",
"ranger",
"glmnet",
"naniar",
"tidyverse",
"caret",
"glmnet",
"ggplot2",
"ggraph",
"gt")
# install.packages("pacman")
library("pacman")
p_load("tm",
"stringi",
"proxy",
"tidyverse",
"sf",
"naniar",
"tidymodels",
"readxl",
"psych",
"ranger",
"glmnet",
"naniar",
"tidyverse",
"caret",
"glmnet",
"ggplot2",
"ggraph",
"gt")
